.gitignore:59:.supabase/*
.gitignore:60:secrets.json
infra/docker-compose.yml:7:      POSTGRES_PASSWORD: postgres
infra/docker-compose.ymly:7:      POSTGRES_PASSWORD: postgres
frontend/package-lock.json:223:    "node_modules/js-tokens": {
frontend/package-lock.json:225:      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
frontend/package-lock.json:235:        "js-tokens": "^3.0.0 || ^4.0.0"
.git/hooks/fsmonitor-watchman.sample:11:# The hook is passed a version (currently 2) and last update token
.git/hooks/fsmonitor-watchman.sample:12:# formatted as a string and outputs to stdout a new update token and
.git/hooks/fsmonitor-watchman.sample:13:# all files that have been modified since the update token. Paths must
.git/hooks/fsmonitor-watchman.sample:19:my ($version, $last_update_token) = @ARGV;
.git/hooks/fsmonitor-watchman.sample:22:# print STDERR "$0 $version $last_update_token\n";
.git/hooks/fsmonitor-watchman.sample:83:	# changed since $last_update_token but not from the .git folder.
.git/hooks/fsmonitor-watchman.sample:90:	if (substr($last_update_token, 0, 1) eq "c") {
.git/hooks/fsmonitor-watchman.sample:91:		$last_update_token = "\"$last_update_token\"";
.git/hooks/fsmonitor-watchman.sample:92:		$last_update_line = qq[\n"since": $last_update_token,];
.git/hooks/fsmonitor-watchman.sample:151:		$last_update_token = $o->{clock};
backend/app/ingestion/common.py:41:    token = str(value).strip().upper()
backend/app/ingestion/common.py:42:    if not token:
backend/app/ingestion/common.py:65:    return mapping.get(token)
backend/app/ingestion/normalizers.py:115:        token = _canon_header(header)
backend/app/ingestion/normalizers.py:116:        canonical = alias_lookup.get(token, token)
backend/app/ingestion/normalizers.py:140:    token = str(value).strip().upper()
backend/app/ingestion/normalizers.py:141:    if not token:
backend/app/ingestion/normalizers.py:143:    if token in BOROUGH_ALIASES:
backend/app/ingestion/normalizers.py:144:        return BOROUGH_ALIASES[token]
backend/app/ingestion/normalizers.py:145:    if token in {"1", "2", "3", "4", "5"}:
backend/app/ingestion/normalizers.py:153:        return mapping.get(token)
backend/app/ingestion/normalizers.py:154:    return token
backend/app/ingestion/normalizers.py:361:    token = value.strip().upper()
backend/app/ingestion/normalizers.py:382:    return mapping.get(token)
backend/app/ingestion/normalizers.py:386:    token = (value or "").strip().lower()
backend/app/ingestion/normalizers.py:387:    token = re.sub(r"\W+", "_", token)
backend/app/ingestion/normalizers.py:388:    token = re.sub(r"_+", "_", token).strip("_")
backend/app/ingestion/normalizers.py:389:    return token
